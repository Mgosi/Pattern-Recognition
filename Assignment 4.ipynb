{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UName : Mahesh Gosi\n",
    "# UBit No : 50290934\n",
    "# UBit Name: mgosi\n",
    "\n",
    "# Introduction to Pattern Recognition\n",
    "## Assignment - 4\n",
    "\n",
    "### Task 1: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks that have one hidden layer are generally known for universal approximation, they can approximate any continuos function. This approximation can be improved by increasing the number of hidden neurons on the network. There is a risk involved with this kind of process, that is a risk of overfitting.\n",
    "\n",
    "A key feature of neural network is that they are able to learn features independently without much human involvement. \n",
    "\n",
    "__Softmax function:__\n",
    "- The softmax function is used as the output layer's activation function. This function will calculate the probabilities of each target class over all possible target classes. This helps us determine the target class for the inputs.\n",
    "- The sum of the probabilities is always equal to 1, as it is a list of probabilities for each class in the system.\n",
    "\n",
    "\n",
    "\n",
    "__Negative Log-likelihood:__\n",
    "\n",
    "- We find the log likelihood and maximize the value to find the parameters of the data. We can also do this by taking the negative log likelihood and minimizing this value.  \n",
    "- This is done by the softmax function to find the maximum likelihood given the data. \n",
    "\n",
    "We update the weights of the neural network through backpropagation. We find the difference between the new weights and current weights and calculate the loss. We propagate this loss to update the weights of the network. Hence by minimizing the loss, we obtain a more accurate model while training.\n",
    "\n",
    "Thus the negative log likelihood helps us get the loss of the neural network when we pass it through the softmax output nodes, by giving the confidence of the likely class and then computing the log of the class.\n",
    "\n",
    "__When given a guassian prior of weight distribution:__\n",
    "\n",
    "Consider that we want to infer some parameter $\\beta $ from some observed input-output pairs. Let us assume that the outputs are linearly related to inputs with some noise $\\epsilon $:\n",
    "\n",
    "\\begin{align}\n",
    " y_n = \\beta x_n + \\epsilon \n",
    "\\end{align}\n",
    "\n",
    "where $\\epsilon$ is the guassian noise. From this we can compute the gussian likelihood:\n",
    "\n",
    "\\begin{align}\n",
    " \\prod_{n=1}^{N} \\mathcal{N}(y_n | \\beta x_n, \\sigma^2 )\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "Now our next step is regularize the parameter $\\beta$ by imposing a guassian prior $\\mathcal{N}(\\beta|0, \\lambda^-1) $\n",
    ", where $\\lambda $ is strictly positive scalar. Hence by combining the likelihood and prior, we have\n",
    "\n",
    "\\begin{align}\n",
    " \\prod_{n=1}^{N} \\mathcal{N}(y_n | \\beta x_n, \\sigma^2 ) \\mathcal{N}(\\beta|0, \\lambda^-1) \n",
    "\\end{align}\n",
    "\n",
    "Now, taking the log of the above expression and ignoring some constants, we have:\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "\\sum_{n=1}^N -\\dfrac{1}{\\sigma^2}(y_n - \\beta x_n)^2 -\\lambda \\beta^2 + c\n",
    "\\end{align}\n",
    "\n",
    "If we maximize the above expression with respect to $\\beta$, we get __Maximum a-posteriori estimate (MAP)__. From this we can say that the gaussian prior can be interpreted as a L2 regularization term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T01:34:30.734606Z",
     "start_time": "2019-04-24T01:34:26.841166Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.regularizers import l2\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T00:06:28.990890Z",
     "start_time": "2019-04-24T00:06:28.544327Z"
    }
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making test sets of 100 images each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T00:06:29.260735Z",
     "start_time": "2019-04-24T00:06:29.184678Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 784), (1000, 784), (1000, 10), (1000, 10))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTrain = x_train[y_train[:,]==0][:100]\n",
    "YTrain = np.zeros(100).tolist()\n",
    "XTest = x_test[y_test[:,]==0][:100]\n",
    "YTest = np.zeros(100).tolist()\n",
    "YTemp = np.empty(100)\n",
    "for i in range(1,10):\n",
    "    XTrain = np.concatenate((XTrain, x_train[y_train[:,]==i][:100]))\n",
    "    YTemp.fill(i)\n",
    "    YTrain = YTrain + YTemp.tolist()\n",
    "    XTest = np.concatenate((XTest, x_test[y_test[:,]==i][:100] ))\n",
    "    YTest = YTest + YTemp.tolist()\n",
    "\n",
    "XTrain = XTrain.reshape(XTrain.shape[0], XTrain.shape[1]*XTrain.shape[2]).astype('float32')/255\n",
    "XTest = XTest.reshape(XTest.shape[0], XTest.shape[1]*XTest.shape[2]).astype('float32')/255\n",
    "YTrain = np_utils.to_categorical(YTrain)\n",
    "YTest = np_utils.to_categorical(YTest)\n",
    "XTrain.shape, XTest.shape, YTrain.shape, YTest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taking 1000 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T00:06:29.701204Z",
     "start_time": "2019-04-24T00:06:29.696015Z"
    }
   },
   "outputs": [],
   "source": [
    "numClasses=YTest.shape[1]\n",
    "noOfPixels = 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T00:06:30.436878Z",
     "start_time": "2019-04-24T00:06:30.429508Z"
    }
   },
   "outputs": [],
   "source": [
    "learn_rate=[]\n",
    "# Class to generate the learining rate based on the callback. \n",
    "class SGDLearningRateTracker(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        optimizer=self.model.optimizer\n",
    "        _lr=tf.to_float(optimizer.lr, name='ToFloat')\n",
    "        _decay=tf.to_float(optimizer.decay, name='ToFloat')\n",
    "        _iter=tf.to_float(optimizer.iterations, name='ToFloat')\n",
    "        \n",
    "        lr=K.eval(_lr *(1./(1. + _decay*_iter)))\n",
    "        learn_rate.append(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T00:06:31.208474Z",
     "start_time": "2019-04-24T00:06:31.198528Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_test=[]\n",
    "acc_test=[]\n",
    "\n",
    "# Classes to generate the loss for training and testing.\n",
    "class TestCallback_test(keras.callbacks.Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data=test_data\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        x,y = self.test_data\n",
    "        loss, acc= self.model.evaluate(x,y, verbose=0)\n",
    "        loss_test.append(loss)\n",
    "        acc_test.append(acc)\n",
    "        \n",
    "loss_train=[]\n",
    "acc_train=[]\n",
    "class TestCallback_train(keras.callbacks.Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data=test_data\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        x,y = self.test_data\n",
    "        loss, acc= self.model.evaluate(x,y, verbose=0)\n",
    "        loss_train.append(loss)\n",
    "        acc_train.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T00:06:32.327900Z",
     "start_time": "2019-04-24T00:06:32.298005Z"
    }
   },
   "outputs": [],
   "source": [
    "# ==== ALL MODELS ===#\n",
    "def Task2_a():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, input_dim=noOfPixels, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.add(Dense(numClasses, kernel_initializer='normal', activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.1,decay=0.001), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def Task2_b1():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, input_dim=noOfPixels, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.add(Dense(30, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.add(Dense(numClasses, kernel_initializer='normal', activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.1,decay=0.00001), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def Task2_b2():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, input_dim=noOfPixels, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.add(Dense(30, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.add(Dense(30, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.add(Dense(numClasses, kernel_initializer='normal', activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.1,decay=0.1), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def Task2_b3():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, input_dim=noOfPixels, kernel_initializer='normal', activation='sigmoid',W_regularizer=l2(5)))\n",
    "    model.add(Dense(numClasses, kernel_initializer='normal', activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.1,decay=0.001), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def Task2_b4():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, input_dim=noOfPixels, kernel_initializer='normal', activation='sigmoid',W_regularizer=l2(5)))\n",
    "    model.add(Dense(30, kernel_initializer='normal', activation='sigmoid',W_regularizer=l2(5)))\n",
    "    model.add(Dense(numClasses, kernel_initializer='normal', activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.1,decay=0.00001), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def Task2_b5():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, input_dim=noOfPixels, kernel_initializer='normal', activation='sigmoid',W_regularizer=l2(5)))\n",
    "    model.add(Dense(30, kernel_initializer='normal', activation='sigmoid',W_regularizer=l2(5)))\n",
    "    model.add(Dense(30, kernel_initializer='normal', activation='sigmoid',W_regularizer=l2(5)))\n",
    "    model.add(Dense(numClasses, kernel_initializer='normal', activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.1,decay=0.0001), metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T00:06:34.273619Z",
     "start_time": "2019-04-24T00:06:34.267461Z"
    }
   },
   "outputs": [],
   "source": [
    "callbacks_list1= [SGDLearningRateTracker(), TestCallback_test((XTest, YTest)), TestCallback_train((XTrain, YTrain))]\n",
    "callbacks_list2= [SGDLearningRateTracker(), TestCallback_test((XTest, YTest)), TestCallback_train((XTrain, YTrain))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T00:06:34.864344Z",
     "start_time": "2019-04-24T00:06:34.859715Z"
    }
   },
   "outputs": [],
   "source": [
    "epoch=[]\n",
    "for i in range(1,31):\n",
    "    epoch.append(i)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T00:07:01.797324Z",
     "start_time": "2019-04-24T00:06:36.918994Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/akash/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 30)                23550     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                310       \n",
      "=================================================================\n",
      "Total params: 23,860\n",
      "Trainable params: 23,860\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /Users/akash/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akash/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning:\n",
      "\n",
      "The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/30\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.2783 - acc: 0.1240 - val_loss: 2.2121 - val_acc: 0.1750\n",
      "WARNING:tensorflow:From <ipython-input-5-e484a104638f>:6: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 1s 996us/step - loss: 2.0619 - acc: 0.4080 - val_loss: 1.9161 - val_acc: 0.5590\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 0s 477us/step - loss: 1.6692 - acc: 0.6340 - val_loss: 1.5476 - val_acc: 0.6330\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 1s 589us/step - loss: 1.3157 - acc: 0.6960 - val_loss: 1.3011 - val_acc: 0.6810\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 1s 829us/step - loss: 1.0782 - acc: 0.7680 - val_loss: 1.1187 - val_acc: 0.7040\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 1s 665us/step - loss: 0.9144 - acc: 0.8040 - val_loss: 0.9981 - val_acc: 0.7220\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 1s 664us/step - loss: 0.7997 - acc: 0.8410 - val_loss: 0.9203 - val_acc: 0.7450\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 1s 524us/step - loss: 0.7121 - acc: 0.8500 - val_loss: 0.8591 - val_acc: 0.7600\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 1s 522us/step - loss: 0.6481 - acc: 0.8610 - val_loss: 0.8077 - val_acc: 0.7680\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 1s 616us/step - loss: 0.5982 - acc: 0.8670 - val_loss: 0.7688 - val_acc: 0.7830\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 0s 486us/step - loss: 0.5556 - acc: 0.8770 - val_loss: 0.7378 - val_acc: 0.7910\n",
      "Epoch 12/30\n",
      "1000/1000 [==============================] - 0s 494us/step - loss: 0.5211 - acc: 0.8810 - val_loss: 0.7114 - val_acc: 0.7880\n",
      "Epoch 13/30\n",
      "1000/1000 [==============================] - 1s 632us/step - loss: 0.4928 - acc: 0.8880 - val_loss: 0.6899 - val_acc: 0.8010\n",
      "Epoch 14/30\n",
      "1000/1000 [==============================] - 1s 535us/step - loss: 0.4665 - acc: 0.8890 - val_loss: 0.6696 - val_acc: 0.8060\n",
      "Epoch 15/30\n",
      "1000/1000 [==============================] - 1s 557us/step - loss: 0.4462 - acc: 0.8930 - val_loss: 0.6536 - val_acc: 0.8100\n",
      "Epoch 16/30\n",
      "1000/1000 [==============================] - 1s 609us/step - loss: 0.4265 - acc: 0.9020 - val_loss: 0.6386 - val_acc: 0.8060\n",
      "Epoch 17/30\n",
      "1000/1000 [==============================] - 0s 479us/step - loss: 0.4095 - acc: 0.9050 - val_loss: 0.6297 - val_acc: 0.8100\n",
      "Epoch 18/30\n",
      "1000/1000 [==============================] - 0s 487us/step - loss: 0.3949 - acc: 0.9140 - val_loss: 0.6185 - val_acc: 0.8150\n",
      "Epoch 19/30\n",
      "1000/1000 [==============================] - 1s 540us/step - loss: 0.3819 - acc: 0.9170 - val_loss: 0.6072 - val_acc: 0.8170\n",
      "Epoch 20/30\n",
      "1000/1000 [==============================] - 0s 490us/step - loss: 0.3703 - acc: 0.9160 - val_loss: 0.5990 - val_acc: 0.8230\n",
      "Epoch 21/30\n",
      "1000/1000 [==============================] - 0s 474us/step - loss: 0.3579 - acc: 0.9240 - val_loss: 0.5936 - val_acc: 0.8210\n",
      "Epoch 22/30\n",
      "1000/1000 [==============================] - 1s 575us/step - loss: 0.3490 - acc: 0.9250 - val_loss: 0.5859 - val_acc: 0.8250\n",
      "Epoch 23/30\n",
      "1000/1000 [==============================] - 0s 484us/step - loss: 0.3388 - acc: 0.9270 - val_loss: 0.5785 - val_acc: 0.8230\n",
      "Epoch 24/30\n",
      "1000/1000 [==============================] - 1s 602us/step - loss: 0.3310 - acc: 0.9290 - val_loss: 0.5728 - val_acc: 0.8230\n",
      "Epoch 25/30\n",
      "1000/1000 [==============================] - 1s 537us/step - loss: 0.3225 - acc: 0.9310 - val_loss: 0.5661 - val_acc: 0.8300\n",
      "Epoch 26/30\n",
      "1000/1000 [==============================] - 1s 538us/step - loss: 0.3157 - acc: 0.9330 - val_loss: 0.5634 - val_acc: 0.8300\n",
      "Epoch 27/30\n",
      "1000/1000 [==============================] - 1s 697us/step - loss: 0.3085 - acc: 0.9310 - val_loss: 0.5575 - val_acc: 0.8330\n",
      "Epoch 28/30\n",
      "1000/1000 [==============================] - 0s 497us/step - loss: 0.3019 - acc: 0.9350 - val_loss: 0.5552 - val_acc: 0.8330\n",
      "Epoch 29/30\n",
      "1000/1000 [==============================] - 0s 497us/step - loss: 0.2961 - acc: 0.9380 - val_loss: 0.5496 - val_acc: 0.8320\n",
      "Epoch 30/30\n",
      "1000/1000 [==============================] - 1s 643us/step - loss: 0.2903 - acc: 0.9380 - val_loss: 0.5466 - val_acc: 0.8340\n"
     ]
    }
   ],
   "source": [
    "#========== Task 2(a) ===============#\n",
    "model1=Task2_a()\n",
    "history1=model1.fit(XTrain, YTrain, validation_data=(XTest, YTest), nb_epoch=30, batch_size=10,\n",
    "verbose=1, callbacks=callbacks_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T00:07:05.163765Z",
     "start_time": "2019-04-24T00:07:02.138022Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akash/anaconda3/lib/python3.7/site-packages/IPython/core/display.py:689: UserWarning:\n",
      "\n",
      "Consider using IPython.display.IFrame instead\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~mgosi/6.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plotly.tools.set_credentials_file(username='mgosi', api_key='X3dKXRZPub6oHfIoFii7')\n",
    "trace1 = go.Scatter(\n",
    "    x=epoch,\n",
    "    y=learn_rate,\n",
    "    name = '<b>2a Learning Rate</b>', # Style name/legend entry with html tags\n",
    "    connectgaps=True\n",
    ")\n",
    "trace2 = go.Scatter(\n",
    "    x=epoch,\n",
    "    y=loss_train,\n",
    "    name = '<b>2a Training Loss</b>', # Style name/legend entry with html tags\n",
    "    connectgaps=True\n",
    ")\n",
    "trace3 = go.Scatter(\n",
    "    x=epoch,\n",
    "    y=loss_test,\n",
    "    name = '<b>2a Testing Loss</b>', # Style name/legend entry with html tags\n",
    "    connectgaps=True\n",
    ")\n",
    "trace4 = go.Scatter(\n",
    "    x=epoch,\n",
    "    y=history1.history[\"val_acc\"],\n",
    "    name = '<b>2a Testing Accuracy</b>', # Style name/legend entry with html tags\n",
    "    connectgaps=True\n",
    ")\n",
    "trace5 = go.Scatter(\n",
    "    x=epoch,\n",
    "    y=history1.history[\"acc\"],\n",
    "    name = '<b>2a Training Accuracy</b>', # Style name/legend entry with html tags\n",
    "    connectgaps=True\n",
    ")\n",
    "data = [trace1, trace2, trace3, trace4, trace5]\n",
    "layout = dict(title = 'Task 2a',\n",
    "              xaxis = dict(title = 'Epoch'),\n",
    "              yaxis = dict(title = 'Loss'),\n",
    "              )\n",
    "fig = dict(data=data, layout = layout)\n",
    "py.iplot(fig, filename='Task2a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T00:07:07.316521Z",
     "start_time": "2019-04-24T00:07:05.661551Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~mgosi/26.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plotly.tools.set_credentials_file(username='mgosi', api_key='X3dKXRZPub6oHfIoFii7')\n",
    "trace1 = go.Scatter(\n",
    "    x=epoch,\n",
    "    y=learn_rate,\n",
    "    name = '<b>2a Learning Rate</b>', # Style name/legend entry with html tags\n",
    "    connectgaps=True\n",
    ")\n",
    "data = [trace1]\n",
    "layout = dict(title = 'Task 2a Learning Rate',\n",
    "              xaxis = dict(title = 'Epoch'),\n",
    "              yaxis = dict(title = 'Rate'),\n",
    "              )\n",
    "fig = dict(data=data, layout = layout)\n",
    "py.iplot(fig, filename='Task 2a Learning Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-23T23:49:05.057961Z",
     "start_time": "2019-04-23T23:48:37.260477Z"
    }
   },
   "source": [
    "## Two Hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T00:07:29.950627Z",
     "start_time": "2019-04-24T00:07:07.802920Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 30)                23550     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                310       \n",
      "=================================================================\n",
      "Total params: 24,790\n",
      "Trainable params: 24,790\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akash/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning:\n",
      "\n",
      "The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/30\n",
      " - 2s - loss: 2.3260 - acc: 0.0850 - val_loss: 2.3149 - val_acc: 0.1000\n",
      "Epoch 2/30\n",
      " - 0s - loss: 2.3253 - acc: 0.0890 - val_loss: 2.3133 - val_acc: 0.1000\n",
      "Epoch 3/30\n",
      " - 0s - loss: 2.3232 - acc: 0.0920 - val_loss: 2.3115 - val_acc: 0.1000\n",
      "Epoch 4/30\n",
      " - 1s - loss: 2.3173 - acc: 0.0970 - val_loss: 2.3221 - val_acc: 0.1000\n",
      "Epoch 5/30\n",
      " - 0s - loss: 2.3171 - acc: 0.0950 - val_loss: 2.3140 - val_acc: 0.1000\n",
      "Epoch 6/30\n",
      " - 0s - loss: 2.3161 - acc: 0.0970 - val_loss: 2.3230 - val_acc: 0.1000\n",
      "Epoch 7/30\n",
      " - 1s - loss: 2.3132 - acc: 0.0940 - val_loss: 2.2978 - val_acc: 0.1870\n",
      "Epoch 8/30\n",
      " - 0s - loss: 2.3103 - acc: 0.0910 - val_loss: 2.2934 - val_acc: 0.1000\n",
      "Epoch 9/30\n",
      " - 0s - loss: 2.2948 - acc: 0.1060 - val_loss: 2.2900 - val_acc: 0.1280\n",
      "Epoch 10/30\n",
      " - 1s - loss: 2.2756 - acc: 0.1500 - val_loss: 2.2610 - val_acc: 0.2100\n",
      "Epoch 11/30\n",
      " - 0s - loss: 2.2475 - acc: 0.1930 - val_loss: 2.2250 - val_acc: 0.2620\n",
      "Epoch 12/30\n",
      " - 0s - loss: 2.1775 - acc: 0.2700 - val_loss: 2.1286 - val_acc: 0.3860\n",
      "Epoch 13/30\n",
      " - 1s - loss: 2.0238 - acc: 0.3810 - val_loss: 1.9524 - val_acc: 0.4170\n",
      "Epoch 14/30\n",
      " - 0s - loss: 1.8053 - acc: 0.4650 - val_loss: 1.7371 - val_acc: 0.4260\n",
      "Epoch 15/30\n",
      " - 0s - loss: 1.5683 - acc: 0.5380 - val_loss: 1.5413 - val_acc: 0.4960\n",
      "Epoch 16/30\n",
      " - 0s - loss: 1.3737 - acc: 0.5830 - val_loss: 1.3781 - val_acc: 0.5570\n",
      "Epoch 17/30\n",
      " - 0s - loss: 1.2199 - acc: 0.6240 - val_loss: 1.2610 - val_acc: 0.5820\n",
      "Epoch 18/30\n",
      " - 0s - loss: 1.0994 - acc: 0.6500 - val_loss: 1.1779 - val_acc: 0.5690\n",
      "Epoch 19/30\n",
      " - 0s - loss: 1.0118 - acc: 0.6720 - val_loss: 1.1202 - val_acc: 0.6080\n",
      "Epoch 20/30\n",
      " - 0s - loss: 0.9373 - acc: 0.7120 - val_loss: 1.0788 - val_acc: 0.5950\n",
      "Epoch 21/30\n",
      " - 0s - loss: 0.8821 - acc: 0.7220 - val_loss: 1.0415 - val_acc: 0.6400\n",
      "Epoch 22/30\n",
      " - 1s - loss: 0.8324 - acc: 0.7280 - val_loss: 1.0188 - val_acc: 0.6340\n",
      "Epoch 23/30\n",
      " - 1s - loss: 0.7861 - acc: 0.7590 - val_loss: 1.0041 - val_acc: 0.6360\n",
      "Epoch 24/30\n",
      " - 1s - loss: 0.7513 - acc: 0.7710 - val_loss: 0.9692 - val_acc: 0.6700\n",
      "Epoch 25/30\n",
      " - 1s - loss: 0.7078 - acc: 0.7900 - val_loss: 0.9714 - val_acc: 0.6720\n",
      "Epoch 26/30\n",
      " - 0s - loss: 0.6763 - acc: 0.8120 - val_loss: 0.9594 - val_acc: 0.6840\n",
      "Epoch 27/30\n",
      " - 0s - loss: 0.6427 - acc: 0.8240 - val_loss: 0.9084 - val_acc: 0.6910\n",
      "Epoch 28/30\n",
      " - 1s - loss: 0.6101 - acc: 0.8300 - val_loss: 0.9054 - val_acc: 0.6980\n",
      "Epoch 29/30\n",
      " - 0s - loss: 0.5771 - acc: 0.8470 - val_loss: 0.8700 - val_acc: 0.7270\n",
      "Epoch 30/30\n",
      " - 0s - loss: 0.5432 - acc: 0.8670 - val_loss: 0.8551 - val_acc: 0.7370\n"
     ]
    }
   ],
   "source": [
    "loss_test=[]\n",
    "acc_test=[]\n",
    "learn_rate=[]\n",
    "loss_train=[]\n",
    "acc_train=[]\n",
    "\n",
    "model2=Task2_b1()\n",
    "history2=model2.fit(XTrain, YTrain, validation_data=(XTest, YTest), nb_epoch=30, batch_size=10,\n",
    "verbose=2, callbacks=callbacks_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T00:07:32.195570Z",
     "start_time": "2019-04-24T00:07:30.347543Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~mgosi/8.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plotly.tools.set_credentials_file(username='mgosi', api_key='X3dKXRZPub6oHfIoFii7')\n",
    "trace1 = go.Scatter(\n",
    "    x=epoch,\n",
    "    y=learn_rate,\n",
    "    name = '<b>2b1 Learning Rate</b>', # Style name/legend entry with html tags\n",
    "    connectgaps=True\n",
    ")\n",
    "trace2 = go.Scatter(\n",
    "    x=epoch,\n",
    "    y=loss_train,\n",
    "    name = '<b>2b1 Training Loss</b>', # Style name/legend entry with html tags\n",
    "    connectgaps=True\n",
    ")\n",
    "trace3 = go.Scatter(\n",
    "    x=epoch,\n",
    "    y=loss_test,\n",
    "    name = '<b>2b1 Testing Loss</b>', # Style name/legend entry with html tags\n",
    "    connectgaps=True\n",
    ")\n",
    "trace4 = go.Scatter(\n",
    "    x=epoch,\n",
    "    y=history2.history[\"val_acc\"],\n",
    "    name = '<b>2b1 Testing Accuracy</b>', # Style name/legend entry with html tags\n",
    "    connectgaps=True\n",
    ")\n",
    "trace5 = go.Scatter(\n",
    "    x=epoch,\n",
    "    y=history2.history[\"acc\"],\n",
    "    name = '<b>2b1 Training Accuracy</b>', # Style name/legend entry with html tags\n",
    "    connectgaps=True\n",
    ")\n",
    "data = [trace1, trace2, trace3, trace4, trace5]\n",
    "layout = dict(title = 'Task 2b1',\n",
    "              xaxis = dict(title = 'Epoch'),\n",
    "              yaxis = dict(title = 'Loss'),\n",
    "              )\n",
    "fig = dict(data=data, layout = layout)\n",
    "py.iplot(fig, filename='Task 2b1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T00:07:34.342631Z",
     "start_time": "2019-04-24T00:07:32.684218Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~mgosi/28.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plotly.tools.set_credentials_file(username='mgosi', api_key='X3dKXRZPub6oHfIoFii7')\n",
    "trace1 = go.Scatter(\n",
    "    x=epoch,\n",
    "    y=learn_rate,\n",
    "    name = '<b>2b1 Learning Rate</b>', # Style name/legend entry with html tags\n",
    "    connectgaps=True\n",
    ")\n",
    "data = [trace1]\n",
    "layout = dict(title = 'Task 2b1 Learning Rate',\n",
    "              xaxis = dict(title = 'Epoch'),\n",
    "              yaxis = dict(title = 'Rate'),\n",
    "              )\n",
    "fig = dict(data=data, layout = layout)\n",
    "py.iplot(fig, filename='Task 2b1 Learning Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-23T23:52:23.083089Z",
     "start_time": "2019-04-23T23:51:58.693284Z"
    }
   },
   "source": [
    "## Three Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T00:08:02.655031Z",
     "start_time": "2019-04-24T00:07:34.840026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 30)                23550     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                310       \n",
      "=================================================================\n",
      "Total params: 25,720\n",
      "Trainable params: 25,720\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akash/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning:\n",
      "\n",
      "The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/30\n",
      " - 2s - loss: 2.3130 - acc: 0.0880 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 2/30\n",
      " - 0s - loss: 2.3052 - acc: 0.0780 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 3/30\n",
      " - 1s - loss: 2.3042 - acc: 0.0920 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 4/30\n",
      " - 0s - loss: 2.3037 - acc: 0.0890 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 5/30\n",
      " - 0s - loss: 2.3035 - acc: 0.0800 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 6/30\n",
      " - 1s - loss: 2.3033 - acc: 0.0790 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 7/30\n",
      " - 0s - loss: 2.3032 - acc: 0.0770 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 8/30\n",
      " - 0s - loss: 2.3031 - acc: 0.0790 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 9/30\n",
      " - 1s - loss: 2.3030 - acc: 0.0820 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 10/30\n",
      " - 0s - loss: 2.3030 - acc: 0.0870 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 11/30\n",
      " - 0s - loss: 2.3029 - acc: 0.0780 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 12/30\n",
      " - 1s - loss: 2.3029 - acc: 0.0920 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 13/30\n",
      " - 0s - loss: 2.3029 - acc: 0.0790 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 14/30\n",
      " - 1s - loss: 2.3029 - acc: 0.0880 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 15/30\n",
      " - 1s - loss: 2.3028 - acc: 0.0820 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 16/30\n",
      " - 1s - loss: 2.3028 - acc: 0.0700 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 17/30\n",
      " - 1s - loss: 2.3028 - acc: 0.0930 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 18/30\n",
      " - 1s - loss: 2.3028 - acc: 0.0810 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 19/30\n",
      " - 1s - loss: 2.3028 - acc: 0.0770 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 20/30\n",
      " - 1s - loss: 2.3028 - acc: 0.0730 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 21/30\n",
      " - 0s - loss: 2.3028 - acc: 0.0770 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 22/30\n",
      " - 1s - loss: 2.3028 - acc: 0.0900 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 23/30\n",
      " - 0s - loss: 2.3028 - acc: 0.0700 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 24/30\n",
      " - 1s - loss: 2.3027 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 25/30\n",
      " - 1s - loss: 2.3027 - acc: 0.0820 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 26/30\n",
      " - 0s - loss: 2.3027 - acc: 0.0740 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 27/30\n",
      " - 1s - loss: 2.3027 - acc: 0.0770 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 28/30\n",
      " - 1s - loss: 2.3027 - acc: 0.0750 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 29/30\n",
      " - 0s - loss: 2.3027 - acc: 0.0800 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 30/30\n",
      " - 0s - loss: 2.3027 - acc: 0.0890 - val_loss: 2.3026 - val_acc: 0.1000\n"
     ]
    }
   ],
   "source": [
    "loss_test=[]\n",
    "acc_test=[]\n",
    "learn_rate=[]\n",
    "loss_train=[]\n",
    "acc_train=[]\n",
    "\n",
    "model3=Task2_b2()\n",
    "history3=model3.fit(XTrain, YTrain, validation_data=(XTest, YTest), nb_epoch=30, batch_size=10,\n",
    "verbose=2, callbacks=callbacks_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T00:08:05.065288Z",
     "start_time": "2019-04-24T00:08:03.086781Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~mgosi/10.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plotly.tools.set_credentials_file(username='mgosi', api_key='X3dKXRZPub6oHfIoFii7')\n",
    "trace1 = go.Scatter(\n",
    "    x=epoch,\n",
    "    y=learn_rate,\n",
    "    name = '<b>2b2 Learning Rate</b>', # Style name/legend entry with html tags\n",
    "    connectgaps=True\n",
    ")\n",
    "trace2 = go.Scatter(\n",
    "    x=epoch,\n",
    "    y=loss_train,\n",
    "    name = '<b>2b2 Training Loss</b>', # Style name/legend entry with html tags\n",
    "    connectgaps=True\n",
    ")\n",
    "trace3 = go.Scatter(\n",
    "    x=epoch,\n",
    "    y=loss_test,\n",
    "    name = '<b>2b2 Testing Loss</b>', # Style name/legend entry with html tags\n",
    "    connectgaps=True\n",
    ")\n",
    "trace4 = go.Scatter(\n",
    "    x=epoch,\n",
    "    y=history2.history[\"val_acc\"],\n",
    "    name = '<b>2b2 Testing Accuracy</b>', # Style name/legend entry with html tags\n",
    "    connectgaps=True\n",
    ")\n",
    "trace5 = go.Scatter(\n",
    "    x=epoch,\n",
    "    y=history2.history[\"acc\"],\n",
    "    name = '<b>2b2 Training Accuracy</b>', # Style name/legend entry with html tags\n",
    "    connectgaps=True\n",
    ")\n",
    "data = [trace1, trace2, trace3, trace4, trace5]\n",
    "layout = dict(title = 'Task 2b2',\n",
    "              xaxis = dict(title = 'Epoch'),\n",
    "              yaxis = dict(title = 'Loss'),\n",
    "              )\n",
    "fig = dict(data=data, layout = layout)\n",
    "py.iplot(fig, filename='Task 2b2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T00:08:07.519482Z",
     "start_time": "2019-04-24T00:08:05.552772Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~mgosi/12.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plotly.tools.set_credentials_file(username='mgosi', api_key='X3dKXRZPub6oHfIoFii7')\n",
    "trace1 = go.Scatter(\n",
    "    x=epoch,\n",
    "    y=learn_rate,\n",
    "    name = '<b>2b2 Learning Rate</b>', # Style name/legend entry with html tags\n",
    "    connectgaps=True\n",
    ")\n",
    "data = [trace1]\n",
    "layout = dict(title = 'Task 2b2 Learning Rate',\n",
    "              xaxis = dict(title = 'Epoch'),\n",
    "              yaxis = dict(title = 'Rate'),\n",
    "              )\n",
    "fig = dict(data=data, layout = layout)\n",
    "py.iplot(fig, filename='Task 2b2 Learning Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T00:08:51.709955Z",
     "start_time": "2019-04-24T00:08:19.305833Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akash/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:31: UserWarning:\n",
      "\n",
      "Update your `Dense` call to the Keras 2 API: `Dense(30, input_dim=784, kernel_initializer=\"normal\", activation=\"sigmoid\", kernel_regularizer=<keras.reg...)`\n",
      "\n",
      "/Users/akash/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: UserWarning:\n",
      "\n",
      "The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 30)                23550     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                310       \n",
      "=================================================================\n",
      "Total params: 23,860\n",
      "Trainable params: 23,860\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/30\n",
      " - 3s - loss: 5.2674 - acc: 0.1060 - val_loss: 2.3198 - val_acc: 0.1000\n",
      "Epoch 2/30\n",
      " - 1s - loss: 2.3200 - acc: 0.1060 - val_loss: 2.3115 - val_acc: 0.1000\n",
      "Epoch 3/30\n",
      " - 1s - loss: 2.3227 - acc: 0.0960 - val_loss: 2.3171 - val_acc: 0.1000\n",
      "Epoch 4/30\n",
      " - 1s - loss: 2.3239 - acc: 0.0880 - val_loss: 2.3057 - val_acc: 0.1000\n",
      "Epoch 5/30\n",
      " - 1s - loss: 2.3176 - acc: 0.0880 - val_loss: 2.3143 - val_acc: 0.1000\n",
      "Epoch 6/30\n",
      " - 1s - loss: 2.3165 - acc: 0.1100 - val_loss: 2.3132 - val_acc: 0.1000\n",
      "Epoch 7/30\n",
      " - 1s - loss: 2.3193 - acc: 0.0880 - val_loss: 2.3129 - val_acc: 0.1000\n",
      "Epoch 8/30\n",
      " - 1s - loss: 2.3204 - acc: 0.0800 - val_loss: 2.3111 - val_acc: 0.1490\n",
      "Epoch 9/30\n",
      " - 1s - loss: 2.3180 - acc: 0.0880 - val_loss: 2.3076 - val_acc: 0.1000\n",
      "Epoch 10/30\n",
      " - 1s - loss: 2.3159 - acc: 0.0910 - val_loss: 2.3076 - val_acc: 0.1000\n",
      "Epoch 11/30\n",
      " - 1s - loss: 2.3170 - acc: 0.0800 - val_loss: 2.3082 - val_acc: 0.1000\n",
      "Epoch 12/30\n",
      " - 0s - loss: 2.3171 - acc: 0.0760 - val_loss: 2.3065 - val_acc: 0.1000\n",
      "Epoch 13/30\n",
      " - 0s - loss: 2.3149 - acc: 0.0880 - val_loss: 2.3080 - val_acc: 0.1000\n",
      "Epoch 14/30\n",
      " - 0s - loss: 2.3162 - acc: 0.0800 - val_loss: 2.3068 - val_acc: 0.1000\n",
      "Epoch 15/30\n",
      " - 0s - loss: 2.3097 - acc: 0.0910 - val_loss: 2.3126 - val_acc: 0.1000\n",
      "Epoch 16/30\n",
      " - 1s - loss: 2.3136 - acc: 0.0950 - val_loss: 2.3061 - val_acc: 0.1000\n",
      "Epoch 17/30\n",
      " - 0s - loss: 2.3152 - acc: 0.0840 - val_loss: 2.3041 - val_acc: 0.1000\n",
      "Epoch 18/30\n",
      " - 0s - loss: 2.3132 - acc: 0.0790 - val_loss: 2.3058 - val_acc: 0.1000\n",
      "Epoch 19/30\n",
      " - 1s - loss: 2.3121 - acc: 0.0880 - val_loss: 2.3055 - val_acc: 0.1000\n",
      "Epoch 20/30\n",
      " - 0s - loss: 2.3109 - acc: 0.0870 - val_loss: 2.3072 - val_acc: 0.1000\n",
      "Epoch 21/30\n",
      " - 1s - loss: 2.3127 - acc: 0.0860 - val_loss: 2.3043 - val_acc: 0.1000\n",
      "Epoch 22/30\n",
      " - 1s - loss: 2.3093 - acc: 0.0970 - val_loss: 2.3081 - val_acc: 0.1000\n",
      "Epoch 23/30\n",
      " - 1s - loss: 2.3107 - acc: 0.0940 - val_loss: 2.3054 - val_acc: 0.1840\n",
      "Epoch 24/30\n",
      " - 1s - loss: 2.3110 - acc: 0.1020 - val_loss: 2.3038 - val_acc: 0.1000\n",
      "Epoch 25/30\n",
      " - 0s - loss: 2.3119 - acc: 0.0830 - val_loss: 2.3042 - val_acc: 0.1000\n",
      "Epoch 26/30\n",
      " - 0s - loss: 2.3108 - acc: 0.0870 - val_loss: 2.3039 - val_acc: 0.1000\n",
      "Epoch 27/30\n",
      " - 1s - loss: 2.3099 - acc: 0.0870 - val_loss: 2.3051 - val_acc: 0.1000\n",
      "Epoch 28/30\n",
      " - 1s - loss: 2.3106 - acc: 0.0810 - val_loss: 2.3047 - val_acc: 0.1000\n",
      "Epoch 29/30\n",
      " - 1s - loss: 2.3110 - acc: 0.0870 - val_loss: 2.3043 - val_acc: 0.1000\n",
      "Epoch 30/30\n",
      " - 1s - loss: 2.3109 - acc: 0.0860 - val_loss: 2.3032 - val_acc: 0.1000\n"
     ]
    }
   ],
   "source": [
    "#===One layer with L2 =====#\n",
    "\n",
    "loss_test=[]\n",
    "acc_test=[]\n",
    "learn_rate=[]\n",
    "loss_train=[]\n",
    "acc_train=[]\n",
    "\n",
    "model4=Task2_b3()\n",
    "history4=model4.fit(XTrain, YTrain, validation_data=(XTest, YTest), nb_epoch=30, batch_size=10,\n",
    "verbose=2, callbacks=callbacks_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T00:08:54.200459Z",
     "start_time": "2019-04-24T00:08:52.183498Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~mgosi/14.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plotly.tools.set_credentials_file(username='mgosi', api_key='X3dKXRZPub6oHfIoFii7')\n",
    "trace1 = go.Scatter(\n",
    "    x=epoch,\n",
    "    y=learn_rate,\n",
    "    name = '<b>2b3 Learning Rate</b>', # Style name/legend entry with html tags\n",
    "    connectgaps=True\n",
    ")\n",
    "trace2 = go.Scatter(\n",
    "    x=epoch,\n",
    "    y=loss_train,\n",
    "    name = '<b>2b3 Training Loss</b>', # Style name/legend entry with html tags\n",
    "    connectgaps=True\n",
    ")\n",
    "trace3 = go.Scatter(\n",
    "    x=epoch,\n",
    "    y=loss_test,\n",
    "    name = '<b>2b3 Testing Loss</b>', # Style name/legend entry with html tags\n",
    "    connectgaps=True\n",
    ")\n",
    "trace4 = go.Scatter(\n",
    "    x=epoch,\n",
    "    y=history2.history[\"val_acc\"],\n",
    "    name = '<b>2b3 Testing Accuracy</b>', # Style name/legend entry with html tags\n",
    "    connectgaps=True\n",
    ")\n",
    "trace5 = go.Scatter(\n",
    "    x=epoch,\n",
    "    y=history2.history[\"acc\"],\n",
    "    name = '<b>2b3 Training Accuracy</b>', # Style name/legend entry with html tags\n",
    "    connectgaps=True\n",
    ")\n",
    "data = [trace1, trace2, trace3, trace4, trace5]\n",
    "layout = dict(title = 'Task 2b3',\n",
    "              xaxis = dict(title = 'Epoch'),\n",
    "              yaxis = dict(title = 'Loss'),\n",
    "              )\n",
    "fig = dict(data=data, layout = layout)\n",
    "py.iplot(fig, filename='Task 2b3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T00:08:56.672987Z",
     "start_time": "2019-04-24T00:08:54.715979Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~mgosi/16.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plotly.tools.set_credentials_file(username='mgosi', api_key='X3dKXRZPub6oHfIoFii7')\n",
    "trace1 = go.Scatter(\n",
    "    x=epoch,\n",
    "    y=learn_rate,\n",
    "    name = '<b>2b3 Learning Rate</b>', # Style name/legend entry with html tags\n",
    "    connectgaps=True\n",
    ")\n",
    "data = [trace1]\n",
    "layout = dict(title = 'Task 2b3 Learning Rate',\n",
    "              xaxis = dict(title = 'Epoch'),\n",
    "              yaxis = dict(title = 'Rate'),\n",
    "              )\n",
    "fig = dict(data=data, layout = layout)\n",
    "py.iplot(fig, filename='Task 2b3 Learning Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T00:09:25.032617Z",
     "start_time": "2019-04-24T00:08:57.039403Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 30)                23550     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                310       \n",
      "=================================================================\n",
      "Total params: 24,790\n",
      "Trainable params: 24,790\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akash/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:39: UserWarning:\n",
      "\n",
      "Update your `Dense` call to the Keras 2 API: `Dense(30, input_dim=784, kernel_initializer=\"normal\", activation=\"sigmoid\", kernel_regularizer=<keras.reg...)`\n",
      "\n",
      "/Users/akash/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:40: UserWarning:\n",
      "\n",
      "Update your `Dense` call to the Keras 2 API: `Dense(30, kernel_initializer=\"normal\", activation=\"sigmoid\", kernel_regularizer=<keras.reg...)`\n",
      "\n",
      "/Users/akash/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: UserWarning:\n",
      "\n",
      "The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/30\n",
      " - 3s - loss: 5.3804 - acc: 0.0850 - val_loss: 2.3171 - val_acc: 0.1000\n",
      "Epoch 2/30\n",
      " - 1s - loss: 2.3292 - acc: 0.0820 - val_loss: 2.3065 - val_acc: 0.1000\n",
      "Epoch 3/30\n",
      " - 1s - loss: 2.3155 - acc: 0.1020 - val_loss: 2.3544 - val_acc: 0.1000\n",
      "Epoch 4/30\n",
      " - 1s - loss: 2.3237 - acc: 0.1080 - val_loss: 2.3151 - val_acc: 0.1000\n",
      "Epoch 5/30\n",
      " - 0s - loss: 2.3276 - acc: 0.0950 - val_loss: 2.3146 - val_acc: 0.1000\n",
      "Epoch 6/30\n",
      " - 1s - loss: 2.3227 - acc: 0.0940 - val_loss: 2.3173 - val_acc: 0.1000\n",
      "Epoch 7/30\n",
      " - 0s - loss: 2.3273 - acc: 0.0810 - val_loss: 2.3185 - val_acc: 0.1000\n",
      "Epoch 8/30\n",
      " - 0s - loss: 2.3272 - acc: 0.0910 - val_loss: 2.3165 - val_acc: 0.1000\n",
      "Epoch 9/30\n",
      " - 1s - loss: 2.3256 - acc: 0.0930 - val_loss: 2.3154 - val_acc: 0.1000\n",
      "Epoch 10/30\n",
      " - 0s - loss: 2.3240 - acc: 0.1020 - val_loss: 2.3148 - val_acc: 0.1000\n",
      "Epoch 11/30\n",
      " - 1s - loss: 2.3274 - acc: 0.0800 - val_loss: 2.3228 - val_acc: 0.1000\n",
      "Epoch 12/30\n",
      " - 0s - loss: 2.3251 - acc: 0.0940 - val_loss: 2.3230 - val_acc: 0.1000\n",
      "Epoch 13/30\n",
      " - 0s - loss: 2.3260 - acc: 0.0980 - val_loss: 2.3254 - val_acc: 0.1000\n",
      "Epoch 14/30\n",
      " - 0s - loss: 2.3283 - acc: 0.0850 - val_loss: 2.3106 - val_acc: 0.1000\n",
      "Epoch 15/30\n",
      " - 0s - loss: 2.3213 - acc: 0.1040 - val_loss: 2.3202 - val_acc: 0.1000\n",
      "Epoch 16/30\n",
      " - 1s - loss: 2.3247 - acc: 0.0950 - val_loss: 2.3126 - val_acc: 0.1000\n",
      "Epoch 17/30\n",
      " - 0s - loss: 2.3240 - acc: 0.0900 - val_loss: 2.3117 - val_acc: 0.1000\n",
      "Epoch 18/30\n",
      " - 0s - loss: 2.3271 - acc: 0.0780 - val_loss: 2.3134 - val_acc: 0.1000\n",
      "Epoch 19/30\n",
      " - 0s - loss: 2.3268 - acc: 0.0770 - val_loss: 2.3088 - val_acc: 0.1000\n",
      "Epoch 20/30\n",
      " - 0s - loss: 2.3225 - acc: 0.0930 - val_loss: 2.3226 - val_acc: 0.1000\n",
      "Epoch 21/30\n",
      " - 1s - loss: 2.3228 - acc: 0.0930 - val_loss: 2.3160 - val_acc: 0.1000\n",
      "Epoch 22/30\n",
      " - 0s - loss: 2.3247 - acc: 0.0890 - val_loss: 2.3228 - val_acc: 0.1000\n",
      "Epoch 23/30\n",
      " - 0s - loss: 2.3247 - acc: 0.0930 - val_loss: 2.3112 - val_acc: 0.1000\n",
      "Epoch 24/30\n",
      " - 0s - loss: 2.3259 - acc: 0.0920 - val_loss: 2.3071 - val_acc: 0.1000\n",
      "Epoch 25/30\n",
      " - 0s - loss: 2.3242 - acc: 0.1020 - val_loss: 2.3113 - val_acc: 0.1000\n",
      "Epoch 26/30\n",
      " - 1s - loss: 2.3283 - acc: 0.0930 - val_loss: 2.3166 - val_acc: 0.1000\n",
      "Epoch 27/30\n",
      " - 0s - loss: 2.3226 - acc: 0.1060 - val_loss: 2.3087 - val_acc: 0.1000\n",
      "Epoch 28/30\n",
      " - 1s - loss: 2.3235 - acc: 0.0920 - val_loss: 2.3129 - val_acc: 0.1000\n",
      "Epoch 29/30\n",
      " - 0s - loss: 2.3251 - acc: 0.0840 - val_loss: 2.3188 - val_acc: 0.1000\n",
      "Epoch 30/30\n",
      " - 1s - loss: 2.3246 - acc: 0.0960 - val_loss: 2.3139 - val_acc: 0.1000\n"
     ]
    }
   ],
   "source": [
    "#=== Two layers with L2 =====#\n",
    "\n",
    "loss_test=[]\n",
    "acc_test=[]\n",
    "learn_rate=[]\n",
    "loss_train=[]\n",
    "acc_train=[]\n",
    "\n",
    "model5=Task2_b4()\n",
    "history5=model5.fit(XTrain, YTrain, validation_data=(XTest, YTest), nb_epoch=30, batch_size=10,\n",
    "verbose=2, callbacks=callbacks_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T00:09:27.086943Z",
     "start_time": "2019-04-24T00:09:25.432409Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~mgosi/20.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plotly.tools.set_credentials_file(username='mgosi', api_key='X3dKXRZPub6oHfIoFii7')\n",
    "trace1 = go.Scatter(\n",
    "    x=epoch,\n",
    "    y=learn_rate,\n",
    "    name = '<b>2b4 Learning Rate</b>', # Style name/legend entry with html tags\n",
    "    connectgaps=True\n",
    ")\n",
    "trace2 = go.Scatter(\n",
    "    x=epoch,\n",
    "    y=loss_train,\n",
    "    name = '<b>2b4 Training Loss</b>', # Style name/legend entry with html tags\n",
    "    connectgaps=True\n",
    ")\n",
    "trace3 = go.Scatter(\n",
    "    x=epoch,\n",
    "    y=loss_test,\n",
    "    name = '<b>2b4 Testing Loss</b>', # Style name/legend entry with html tags\n",
    "    connectgaps=True\n",
    ")\n",
    "trace4 = go.Scatter(\n",
    "    x=epoch,\n",
    "    y=history2.history[\"val_acc\"],\n",
    "    name = '<b>2b4 Testing Accuracy</b>', # Style name/legend entry with html tags\n",
    "    connectgaps=True\n",
    ")\n",
    "trace5 = go.Scatter(\n",
    "    x=epoch,\n",
    "    y=history2.history[\"acc\"],\n",
    "    name = '<b>2b4 Training Accuracy</b>', # Style name/legend entry with html tags\n",
    "    connectgaps=True\n",
    ")\n",
    "data = [trace1, trace2, trace3, trace4, trace5]\n",
    "layout = dict(title = 'Task 2b4',\n",
    "              xaxis = dict(title = 'Epoch'),\n",
    "              yaxis = dict(title = 'Loss'),\n",
    "              )\n",
    "fig = dict(data=data, layout = layout)\n",
    "py.iplot(fig, filename='Task 2b4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T00:09:29.319594Z",
     "start_time": "2019-04-24T00:09:27.544180Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~mgosi/18.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plotly.tools.set_credentials_file(username='mgosi', api_key='X3dKXRZPub6oHfIoFii7')\n",
    "trace1 = go.Scatter(\n",
    "    x=epoch,\n",
    "    y=learn_rate,\n",
    "    name = '<b>2b4 Learning Rate</b>', # Style name/legend entry with html tags\n",
    "    connectgaps=True\n",
    ")\n",
    "data = [trace1]\n",
    "layout = dict(title = 'Task 2b4 Learning Rate',\n",
    "              xaxis = dict(title = 'Epoch'),\n",
    "              yaxis = dict(title = 'Rate'),\n",
    "              )\n",
    "fig = dict(data=data, layout = layout)\n",
    "py.iplot(fig, filename='Task 2b4 Learning Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T00:01:22.624491Z",
     "start_time": "2019-04-24T00:01:20.840611Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T00:10:04.989633Z",
     "start_time": "2019-04-24T00:09:29.747984Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 30)                23550     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                310       \n",
      "=================================================================\n",
      "Total params: 25,720\n",
      "Trainable params: 25,720\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akash/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:48: UserWarning:\n",
      "\n",
      "Update your `Dense` call to the Keras 2 API: `Dense(30, input_dim=784, kernel_initializer=\"normal\", activation=\"sigmoid\", kernel_regularizer=<keras.reg...)`\n",
      "\n",
      "/Users/akash/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:49: UserWarning:\n",
      "\n",
      "Update your `Dense` call to the Keras 2 API: `Dense(30, kernel_initializer=\"normal\", activation=\"sigmoid\", kernel_regularizer=<keras.reg...)`\n",
      "\n",
      "/Users/akash/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:50: UserWarning:\n",
      "\n",
      "Update your `Dense` call to the Keras 2 API: `Dense(30, kernel_initializer=\"normal\", activation=\"sigmoid\", kernel_regularizer=<keras.reg...)`\n",
      "\n",
      "/Users/akash/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: UserWarning:\n",
      "\n",
      "The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/30\n",
      " - 3s - loss: 5.4819 - acc: 0.0920 - val_loss: 2.3197 - val_acc: 0.1000\n",
      "Epoch 2/30\n",
      " - 1s - loss: 2.3274 - acc: 0.0800 - val_loss: 2.3092 - val_acc: 0.1000\n",
      "Epoch 3/30\n",
      " - 1s - loss: 2.3290 - acc: 0.0920 - val_loss: 2.3083 - val_acc: 0.1000\n",
      "Epoch 4/30\n",
      " - 1s - loss: 2.3224 - acc: 0.0850 - val_loss: 2.3127 - val_acc: 0.1000\n",
      "Epoch 5/30\n",
      " - 1s - loss: 2.3216 - acc: 0.0920 - val_loss: 2.3157 - val_acc: 0.1000\n",
      "Epoch 6/30\n",
      " - 1s - loss: 2.3251 - acc: 0.0960 - val_loss: 2.3095 - val_acc: 0.1000\n",
      "Epoch 7/30\n",
      " - 1s - loss: 2.3206 - acc: 0.0880 - val_loss: 2.3239 - val_acc: 0.1000\n",
      "Epoch 8/30\n",
      " - 1s - loss: 2.3233 - acc: 0.0950 - val_loss: 2.3092 - val_acc: 0.1000\n",
      "Epoch 9/30\n",
      " - 1s - loss: 2.3204 - acc: 0.0840 - val_loss: 2.3229 - val_acc: 0.1000\n",
      "Epoch 10/30\n",
      " - 1s - loss: 2.3251 - acc: 0.0960 - val_loss: 2.3109 - val_acc: 0.1000\n",
      "Epoch 11/30\n",
      " - 1s - loss: 2.3147 - acc: 0.0970 - val_loss: 2.3421 - val_acc: 0.1000\n",
      "Epoch 12/30\n",
      " - 1s - loss: 2.3260 - acc: 0.0890 - val_loss: 2.3102 - val_acc: 0.1000\n",
      "Epoch 13/30\n",
      " - 1s - loss: 2.3182 - acc: 0.0980 - val_loss: 2.3139 - val_acc: 0.1000\n",
      "Epoch 14/30\n",
      " - 1s - loss: 2.3272 - acc: 0.0920 - val_loss: 2.3087 - val_acc: 0.1000\n",
      "Epoch 15/30\n",
      " - 1s - loss: 2.3248 - acc: 0.0830 - val_loss: 2.3134 - val_acc: 0.1000\n",
      "Epoch 16/30\n",
      " - 1s - loss: 2.3193 - acc: 0.0780 - val_loss: 2.3180 - val_acc: 0.1000\n",
      "Epoch 17/30\n",
      " - 1s - loss: 2.3247 - acc: 0.0950 - val_loss: 2.3073 - val_acc: 0.1000\n",
      "Epoch 18/30\n",
      " - 1s - loss: 2.3226 - acc: 0.0870 - val_loss: 2.3148 - val_acc: 0.1000\n",
      "Epoch 19/30\n",
      " - 1s - loss: 2.3165 - acc: 0.0900 - val_loss: 2.3149 - val_acc: 0.1000\n",
      "Epoch 20/30\n",
      " - 1s - loss: 2.3229 - acc: 0.0850 - val_loss: 2.3177 - val_acc: 0.1000\n",
      "Epoch 21/30\n",
      " - 1s - loss: 2.3203 - acc: 0.1020 - val_loss: 2.3158 - val_acc: 0.1000\n",
      "Epoch 22/30\n",
      " - 1s - loss: 2.3216 - acc: 0.0760 - val_loss: 2.3171 - val_acc: 0.1000\n",
      "Epoch 23/30\n",
      " - 1s - loss: 2.3202 - acc: 0.0890 - val_loss: 2.3123 - val_acc: 0.1000\n",
      "Epoch 24/30\n",
      " - 1s - loss: 2.3225 - acc: 0.0860 - val_loss: 2.3104 - val_acc: 0.1000\n",
      "Epoch 25/30\n",
      " - 1s - loss: 2.3168 - acc: 0.0960 - val_loss: 2.3210 - val_acc: 0.1000\n",
      "Epoch 26/30\n",
      " - 1s - loss: 2.3213 - acc: 0.0940 - val_loss: 2.3072 - val_acc: 0.1000\n",
      "Epoch 27/30\n",
      " - 1s - loss: 2.3188 - acc: 0.1050 - val_loss: 2.3062 - val_acc: 0.1000\n",
      "Epoch 28/30\n",
      " - 1s - loss: 2.3208 - acc: 0.0830 - val_loss: 2.3113 - val_acc: 0.1000\n",
      "Epoch 29/30\n",
      " - 2s - loss: 2.3196 - acc: 0.1000 - val_loss: 2.3109 - val_acc: 0.1000\n",
      "Epoch 30/30\n",
      " - 1s - loss: 2.3228 - acc: 0.0930 - val_loss: 2.3125 - val_acc: 0.1000\n"
     ]
    }
   ],
   "source": [
    "#===== THree hidden layers with L2 ======#\n",
    "loss_test=[]\n",
    "acc_test=[]\n",
    "learn_rate=[]\n",
    "loss_train=[]\n",
    "acc_train=[]\n",
    "\n",
    "model6=Task2_b5()\n",
    "history6=model6.fit(XTrain, YTrain, validation_data=(XTest, YTest), nb_epoch=30, batch_size=10,\n",
    "verbose=2, callbacks=callbacks_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T00:10:07.334216Z",
     "start_time": "2019-04-24T00:10:05.497777Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~mgosi/22.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plotly.tools.set_credentials_file(username='mgosi', api_key='X3dKXRZPub6oHfIoFii7')\n",
    "trace1 = go.Scatter(\n",
    "    x=epoch,\n",
    "    y=learn_rate,\n",
    "    name = '<b>2b5 Learning Rate</b>', # Style name/legend entry with html tags\n",
    "    connectgaps=True\n",
    ")\n",
    "trace2 = go.Scatter(\n",
    "    x=epoch,\n",
    "    y=loss_train,\n",
    "    name = '<b>2b5 Training Loss</b>', # Style name/legend entry with html tags\n",
    "    connectgaps=True\n",
    ")\n",
    "trace3 = go.Scatter(\n",
    "    x=epoch,\n",
    "    y=loss_test,\n",
    "    name = '<b>2b5 Testing Loss</b>', # Style name/legend entry with html tags\n",
    "    connectgaps=True\n",
    ")\n",
    "trace4 = go.Scatter(\n",
    "    x=epoch,\n",
    "    y=history2.history[\"val_acc\"],\n",
    "    name = '<b>2b5 Testing Accuracy</b>', # Style name/legend entry with html tags\n",
    "    connectgaps=True\n",
    ")\n",
    "trace5 = go.Scatter(\n",
    "    x=epoch,\n",
    "    y=history2.history[\"acc\"],\n",
    "    name = '<b>2b5 Training Accuracy</b>', # Style name/legend entry with html tags\n",
    "    connectgaps=True\n",
    ")\n",
    "data = [trace1, trace2, trace3, trace4, trace5]\n",
    "layout = dict(title = 'Task 2b5',\n",
    "              xaxis = dict(title = 'Epoch'),\n",
    "              yaxis = dict(title = 'Loss'),\n",
    "              )\n",
    "fig = dict(data=data, layout = layout)\n",
    "py.iplot(fig, filename='Task 2b5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T00:10:09.785439Z",
     "start_time": "2019-04-24T00:10:07.936168Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~mgosi/24.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plotly.tools.set_credentials_file(username='mgosi', api_key='X3dKXRZPub6oHfIoFii7')\n",
    "trace1 = go.Scatter(\n",
    "    x=epoch,\n",
    "    y=learn_rate,\n",
    "    name = '<b>2b5 Learning Rate</b>', # Style name/legend entry with html tags\n",
    "    connectgaps=True\n",
    ")\n",
    "data = [trace1]\n",
    "layout = dict(title = 'Task 2b5 Learning Rate',\n",
    "              xaxis = dict(title = 'Epoch'),\n",
    "              yaxis = dict(title = 'Rate'),\n",
    "              )\n",
    "fig = dict(data=data, layout = layout)\n",
    "py.iplot(fig, filename='Task 2b5 Learning Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T00:46:51.564230Z",
     "start_time": "2019-04-24T00:46:50.822259Z"
    }
   },
   "outputs": [],
   "source": [
    "scores1 = model1.evaluate(XTest, YTest, verbose=0)\n",
    "scores2 = model2.evaluate(XTest, YTest, verbose=0)\n",
    "scores3 = model3.evaluate(XTest, YTest, verbose=0)\n",
    "scores4 = model4.evaluate(XTest, YTest, verbose=0)\n",
    "scores5 = model5.evaluate(XTest, YTest, verbose=0)\n",
    "scores6 = model6.evaluate(XTest, YTest, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T00:49:13.452939Z",
     "start_time": "2019-04-24T00:49:13.430511Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss and Accuracy of the models are as follows :\n",
      "[0.5465954859256744, 0.834]\n",
      "[0.8550777387619019, 0.737]\n",
      "[2.3025833435058596, 0.1]\n",
      "[2.30324348449707, 0.1]\n",
      "[2.3139245147705076, 0.1]\n",
      "[2.3124769325256347, 0.1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss and Accuracy of the models are as follows :\")\n",
    "print (scores1)\n",
    "print (scores2)\n",
    "print (scores3)\n",
    "print (scores4)\n",
    "print (scores5)\n",
    "print (scores6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T00:48:07.088491Z",
     "start_time": "2019-04-24T00:48:07.080553Z"
    }
   },
   "source": [
    "## Task 2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T01:38:49.957594Z",
     "start_time": "2019-04-24T01:38:49.530600Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import rotate\n",
    "from scipy.misc import face\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T01:34:37.700831Z",
     "start_time": "2019-04-24T01:34:37.663818Z"
    }
   },
   "outputs": [],
   "source": [
    "#This is used to rotate the images by the desired amount. \n",
    "#It also shifts the pixels in 8 directions.i.e : Right, Left, Top, Down, and all four Diagonals\n",
    "def imgaugment(angle):\n",
    "    \n",
    "    for i in range(0,60000):\n",
    "    #anticlockwise rotation\n",
    "        rot = rotate(X_train[i], angle=angle, reshape=False)\n",
    "\n",
    "        #left shift\n",
    "        for k in range(14,17):\n",
    "            temp=rot[k][0]\n",
    "            for l in range(27):\n",
    "                rot[k][l]=rot[k][l+1]\n",
    "            rot[k][27]=temp\n",
    "        #right shift    \n",
    "        for k in range(22,25):\n",
    "            temp=rot[k][27]\n",
    "            for l in range(27):\n",
    "                rot[k][27-l]=rot[k][27-l-1]\n",
    "            rot[k][0]=temp\n",
    "        #top shift    \n",
    "        for k in range(17,20):\n",
    "            temp=rot[0][k]\n",
    "            for l in range(27):\n",
    "                rot[l][k]=rot[l+1][k]\n",
    "            rot[27][k]=temp\n",
    "        #bottom shift    \n",
    "        for k in range(14,17):\n",
    "            temp=rot[27][k]\n",
    "            for l in range(27):\n",
    "                rot[27-l][k]=rot[27-l-1][k]\n",
    "            rot[0][k]=temp\n",
    "\n",
    "        #second diagonal shift left\n",
    "        b=[]\n",
    "        for i in range(0,28):\n",
    "            b.append(rot[27-i][i])\n",
    "\n",
    "        temp=b[0]\n",
    "\n",
    "        for i in range(0,5):\n",
    "            b[i]=b[i+1]\n",
    "        b[5]=temp\n",
    "\n",
    "        for i in range(0,28):\n",
    "            rot[27-i][i]=b[i]\n",
    "\n",
    "        #first diagonal shift left\n",
    "        c=[]\n",
    "\n",
    "        for i in range(0,28):\n",
    "            c.append(rot[i][i])\n",
    "\n",
    "\n",
    "        temp=c[0]\n",
    "        for i in range(0,27):\n",
    "            c[i]=c[i+1]\n",
    "        c[27]=temp\n",
    "\n",
    "\n",
    "        for i in range(0,28):\n",
    "            rot[i][i]=c[i]\n",
    "\n",
    "        #second diagonal shift right\n",
    "        temp=b[27]\n",
    "        for i in range(0,27):\n",
    "            b[27-i]=b[27-i-1]\n",
    "        b[0]=temp\n",
    "\n",
    "\n",
    "        for i in range(0,28):\n",
    "            rot[27-i][i]=b[i]\n",
    "\n",
    "        #first diagonal rotation right\n",
    "\n",
    "        temp=c[27]\n",
    "        for i in range(0,27):\n",
    "            c[27-i]=c[27-i-1]\n",
    "        c[0]=temp\n",
    "\n",
    "\n",
    "        for i in range(0,28):\n",
    "            rot[i][i]=c[i]\n",
    "\n",
    "\n",
    "        #plt.imshow(rot.reshape(28,28))\n",
    "\n",
    "        #plt.show()\n",
    "        X_train[i]=rot[i]\n",
    "\n",
    "\n",
    "    for i in range(0,10000):\n",
    "\n",
    "        rot1 = rotate(X_test[i], angle=angle, reshape=False)\n",
    "\n",
    "        #left shift\n",
    "        for k in range(22,25):\n",
    "            temp=rot1[k][0]\n",
    "            for l in range(27):\n",
    "                rot1[k][l]=rot1[k][l+1]\n",
    "            rot1[k][27]=temp\n",
    "        #right shift    \n",
    "        for k in range(22,25):\n",
    "            temp=rot1[k][27]\n",
    "            for l in range(27):\n",
    "                rot1[k][27-l]=rot1[k][27-l-1]\n",
    "            rot1[k][0]=temp\n",
    "        #top shift    \n",
    "        for k in range(22,25):\n",
    "            temp=rot1[0][k]\n",
    "            for l in range(27):\n",
    "                rot1[l][k]=rot1[l+1][k]\n",
    "            rot1[27][k]=temp\n",
    "        #bottom shift    \n",
    "        for k in range(22,25):\n",
    "            temp=rot1[27][k]\n",
    "            for l in range(27):\n",
    "                rot1[27-l][k]=rot1[27-l-1][k]\n",
    "            rot1[0][k]=temp\n",
    "\n",
    "        #second diagonal shift left\n",
    "        b=[]\n",
    "        for i in range(0,28):\n",
    "            b.append(rot1[27-i][i])\n",
    "\n",
    "        temp=b[0]\n",
    "\n",
    "        for i in range(0,5):\n",
    "            b[i]=b[i+1]\n",
    "        b[5]=temp\n",
    "\n",
    "        for i in range(0,28):\n",
    "            rot1[27-i][i]=b[i]\n",
    "\n",
    "        #second diagonal shift right\n",
    "        temp=b[27]\n",
    "        for i in range(0,27):\n",
    "            b[27-i]=b[27-i-1]\n",
    "        b[0]=temp\n",
    "\n",
    "\n",
    "        for i in range(0,28):\n",
    "            rot1[27-i][i]=b[i]\n",
    "\n",
    "        #first diagonal shift left\n",
    "        c=[]\n",
    "\n",
    "        for i in range(0,28):\n",
    "            c.append(rot1[i][i])\n",
    "\n",
    "\n",
    "        temp=c[0]\n",
    "        for i in range(0,27):\n",
    "            c[i]=c[i+1]\n",
    "        c[27]=temp\n",
    "\n",
    "\n",
    "        for i in range(0,28):\n",
    "            rot1[i][i]=c[i]\n",
    "\n",
    "        #first diagonal shift right\n",
    "\n",
    "        temp=c[27]\n",
    "        for i in range(0,27):\n",
    "            c[27-i]=c[27-i-1]\n",
    "        c[0]=temp\n",
    "\n",
    "\n",
    "        for i in range(0,28):\n",
    "            rot1[i][i]=c[i]\n",
    "\n",
    "\n",
    "        #plt.imshow(rot1.reshape(28,28))\n",
    "\n",
    "        #plt.show()\n",
    "        X_test[i]=rot1[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T01:35:18.655151Z",
     "start_time": "2019-04-24T01:34:44.490949Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T01:35:18.655151Z",
     "start_time": "2019-04-24T01:34:44.490949Z"
    }
   },
   "outputs": [],
   "source": [
    "imgaugment(2)\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T01:36:26.280727Z",
     "start_time": "2019-04-24T01:36:26.273009Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T01:37:44.432739Z",
     "start_time": "2019-04-24T01:37:44.326176Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "XTrain = X_train[y_train[:,]==0][:100]\n",
    "YTrain = np.zeros(100).tolist()\n",
    "XTest = X_test[y_test[:,]==0][:100]\n",
    "YTest = np.zeros(100).tolist()\n",
    "YTemp = np.empty(100)\n",
    "for i in range(1,10):\n",
    "    XTrain = np.concatenate((XTrain, X_train[y_train[:,]==i][:100]))\n",
    "    YTemp.fill(i)\n",
    "    YTrain = YTrain + YTemp.tolist()\n",
    "    XTest = np.concatenate((XTest, X_test[y_test[:,]==i][:100] ))\n",
    "    YTest = YTest + YTemp.tolist()\n",
    "\n",
    "print (XTrain.shape)\n",
    "XTrain = XTrain/255\n",
    "XTest = XTest/255\n",
    "YTrain = np_utils.to_categorical(YTrain)\n",
    "YTest = np_utils.to_categorical(YTest)\n",
    "XTrain.shape, XTest.shape, YTrain.shape, YTest.shape\n",
    "\n",
    "numOfClasses = YTest.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T01:37:49.546779Z",
     "start_time": "2019-04-24T01:37:49.535234Z"
    }
   },
   "outputs": [],
   "source": [
    "def task3_1():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (5, 5), input_shape=(1, 28, 28), activation='relu', data_format=\"channels_first\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(numOfClasses, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def task3_2():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (5, 5), input_shape=(1, 28, 28), activation='relu', data_format = \"channels_first\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(numOfClasses, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-24T01:38:52.777Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/akash/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "model1= task3_1()\n",
    "history1=model1.fit(XTrain, YTrain, validation_data=(XTest, YTest), epochs=10, batch_size=200, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T01:38:57.698368Z",
     "start_time": "2019-04-24T01:38:57.606996Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'task3_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f4e7aa39d677>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#===== With Dropout ====#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtask3_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mhistory2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXTest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYTest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'task3_2' is not defined"
     ]
    }
   ],
   "source": [
    "#===== With Dropout ====#\n",
    "model2= task3_2()\n",
    "history2=model2.fit(XTrain, YTrain, validation_data=(XTest, YTest), epochs=10, batch_size=200, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
