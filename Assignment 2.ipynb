{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 2: Linear Discriminant Function and Support Vector Machines\n",
    "## Name : Mahesh Gosi\n",
    "## UbitName : mgosi\n",
    "## Person No. : 50290934"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T18:49:53.199813Z",
     "start_time": "2019-03-15T18:49:53.195477Z"
    }
   },
   "outputs": [],
   "source": [
    "from mlxtend.data import loadlocal_mnist\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2 as cv\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T18:49:54.617228Z",
     "start_time": "2019-03-15T18:49:54.539256Z"
    }
   },
   "outputs": [],
   "source": [
    "trainImgs, trainLabels = loadlocal_mnist( \n",
    "        images_path='train-images-idx3-ubyte',\n",
    "        labels_path='train-labels-idx1-ubyte')\n",
    "testImgs, testLabels = loadlocal_mnist( \n",
    "        images_path='t10k-images-idx3-ubyte',\n",
    "        labels_path='t10k-labels-idx1-ubyte')\n",
    "trainImgs = trainImgs.reshape(60000, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 : SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-17T01:37:36.655120Z",
     "start_time": "2019-03-17T01:23:41.338405Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akash/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/akash/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/akash/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/akash/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/akash/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[84.56, 85.72, 87.71, 88.66000000000001, 84.37]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_vals = [0.1, 0.5, 1.0, 2, 3]\n",
    "accuracy = []\n",
    "predictLabels = []\n",
    "for i in range(5):\n",
    "    Classifer = LinearSVC(C = C_vals[i])\n",
    "    Classifer.fit(trainImgs, trainLabels)\n",
    "    predictLabels = Classifer.predict(testImgs)\n",
    "    accuracy.append((predictLabels == testLabels).sum()/len(predictLabels)*100)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-17T03:07:37.272837Z",
     "start_time": "2019-03-17T03:07:37.265994Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 0.1 is : 84.56\n",
      "Accuracy for 0.5 is : 85.72\n",
      "Accuracy for 1.0 is : 87.71\n",
      "Accuracy for 2 is : 88.66000000000001\n",
      "Accuracy for 3 is : 84.37\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(C_vals)):\n",
    "    print (\"Accuracy for \" + str(C_vals[i])+ \" is : \" + str(accuracy[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are performing SVM using Linear kernel with the C parameter. The C Parameter tells us how much to avoid misclassifying the training example. \n",
    "If we keep a high value of C, the optimizer will choose a smaller marging for the hyperplane. Else, a smaller value will tell the optimizer to find a larger margin separating the hyperplane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T23:15:51.230056Z",
     "start_time": "2019-03-16T23:15:51.223196Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[175640.0, 170540.0, 173480.0, 175780.0, 173860.0]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = []\n",
    "for i in range(5):\n",
    "    accuracy.append((predictLabels[i] == testLabels).sum()/len(predictLabels)*100)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T20:54:50.191813Z",
     "start_time": "2019-03-16T20:54:50.154987Z"
    }
   },
   "source": [
    "## Part 2 : Margin in Primal and Dual Formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the Lagrange Dual problem with the Primal Problem as follows :\n",
    "\\begin{align}\n",
    "\\text{minimize } \\frac{1}{2}w^T.w+C \\sum_{n=1}^{N} \\xi_{i}\n",
    "\\\\\n",
    "\\text{subject to } y_i.(w^T.x_i) \\geq {1-\\xi_{i}} \\text{ and } \\xi_i \\geq 0 \\text{ for i }=1,...,N\n",
    "\\end{align}\n",
    "\n",
    "We have to minimize this function by maximizing the margin of the primal problem.\n",
    "\n",
    "The margin is :\n",
    " $\\gamma = \\frac{1}{\\sqrt{w^T.w +C \\sum_{i=1}^{N} \\xi_i }}$\n",
    " \n",
    "We do this by using the Lagrange Function which is given by the following :\n",
    "\n",
    "Lagrange function :\n",
    "\\begin{align}\n",
    "{\\mathcal{L}} = \\frac{1}{2} {\\overrightarrow{w}}^T\\overrightarrow{w} + C \\sum_{i=1}^N\\xi_i + \\Sigma_i\\alpha_i(1-y_i.w^Tx_i -\\xi_i) - \\sum_{i=1}^N \\beta_i \\xi_i\n",
    "\\end{align}\n",
    "\\begin{align}\n",
    "Where, \\alpha, \\beta \\text{ -> Lagrange Multipliers,}\\\\  \\xi\\text{  -> Error through separating vector }\n",
    "\\end{align}\n",
    "\n",
    "Using this we find the Dual Solution. We claim the following <br>\n",
    "<center>$\\underbrace{\\underset{\\alpha,\\beta}{max} \\underset{w,\\xi}{min} \\mathcal{L}}_\\text{dual solution} \\leq \\underbrace{\\underset{w,\\xi}{min} \\underset{\\alpha,\\beta}{max} \\mathcal{L}}_\\text{primal solution}$</center>\n",
    "\n",
    "We find the partial derivative of the Lagrange Function to find the values of <i>w</i> and <i>C</i>\n",
    "\n",
    "\\begin{align}\n",
    "  \\frac{\\partial_{\\mathcal{L}}}{\\partial_w} = w - \\sum_i \\alpha_i y_i x_i = 0 \\implies w = \\sum_i \\alpha_i y_i \\overrightarrow{x_i}\n",
    "\\end{align}\n",
    " \\begin{align} \\frac{\\partial_{\\mathcal{L}}}{\\partial_\\xi} = 0 \\implies C - \\alpha_i - \\beta_i = 0\n",
    "\\end{align} \n",
    "\\begin{align} \\implies 0 \\leq \\alpha_i \\leq C \\text{ and } \\beta_i \\geq 0\n",
    "\\end{align}\n",
    "\n",
    "This shows the multiplier alpha is between 0 and C. \n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "\\text {By Substituting } w = \\sum_i \\alpha_i y_i \\overrightarrow{x_i}, C=\\alpha_i + \\beta_i\n",
    "\\text { into Lagrange function, we get the dual problem of maximizing: }\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "{\\mathcal{L}} = \\frac{1}{2} w^T \\sum_i \\alpha_i y_i \\overrightarrow{x_i} + (\\alpha_i + \\beta_i) \\sum_{i=1}^N\\xi_i + \\Sigma_i\\alpha_i(1-y_i.w^Tx_i -\\xi_i) - \\sum_{i=1}^N \\beta_i \\xi_i\n",
    "\\\\= \\frac{1}{2} w^T \\sum_i \\alpha_i y_i \\overrightarrow{x_i} + \\alpha_i\\sum_{i=1}^N\\xi_i + \\beta_i \\sum_{i=1}^N\\xi_i +\\sum_i \\alpha_i - w^T \\sum_i \\alpha_i y_i \\overrightarrow{x_i} - \\sum_i \\alpha_i \\xi_i - \\sum_{i=1}^N \\beta_i \\xi_i\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "\\\\=\\sum_i \\alpha_i- \\frac{1}{2} \\sum_{i,j} \\alpha_i \\alpha_j y_i y_j (\\overrightarrow{x_i}^T x_j )\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "Hence by substituting the <i>w</i> in the Primal Margin, we get the Dual Margin. With this, we can see the two margins as the following : <br><br>\n",
    "The primal margin is :\n",
    "\\begin{align}\\gamma = \\frac{1}{\\sqrt{w^T.w +C \\sum_{i=1}^{N} \\xi_i }}\\end{align}\n",
    " \n",
    "The dual margin is :\n",
    "\\begin{align}\\gamma = \\frac{1}{\\sqrt{\\alpha_i \\alpha_j y_i y_j (x_i^T x_j )}}\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Benefits of Maximizing the Margin</b> <br>\n",
    "* Maximizing the margin corresponds to a regularization of SVM weights which will prevent overfitting and underfitting of the model. \n",
    "* It makes no low certainty classification decisions. \n",
    "* This helps the model to be more generic so that even if more data is added to the model, the margin will be able to classify the samples correctly.\n",
    "\n",
    "Reference : https://www.quora.com/Why-would-we-prefer-a-large-margin-running-a-SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Categorizes of Support Vectors :<br></b>\n",
    "The SVM Solution has different support vectors which are given by: <br>\n",
    "* If the vector is lying on the margin boundary $w^Tx = -1$ and $w^Tx = 1 (\\text { if } \\xi_i = 0)$\n",
    "* If the vector is lying on the margin region ($0 < \\xi < 1$) but on the correct side\n",
    "* If the vector is on the wrong side of the hyperplane ($\\xi \\geq 1$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Benefits of solving Dual Problem instead of Primal Problem</b>\n",
    "* Solving the dual helps when we have to apply Kernel Trick to classify the data which is not linearly separable. \n",
    "* The number of data points is lower than the number of dimensions\n",
    "* The dual adapts to the amount of available data instead of the dimension.\n",
    "\n",
    "Reference : https://www.quora.com/Why-is-solving-in-the-dual-easier-than-solving-in-the-primal-What-advantages-do-we-get-from-solving-in-the-dual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T22:28:38.230860Z",
     "start_time": "2019-03-16T22:28:38.112260Z"
    }
   },
   "source": [
    "## Part 3 : Multi-Class Dual Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-17T00:58:40.726873Z",
     "start_time": "2019-03-17T00:58:40.708815Z"
    }
   },
   "source": [
    "This is the Primal problem for the Multi-Class Problem :<br>\n",
    "\\begin{equation}\n",
    "\\underset{w_{m}\\in H,\\xi \\in R^l}{min} \\frac{1}{2} \\sum_{m=1}^{k} w_{m}^{T} w_{m} + C \\sum_{i=1}^{l}  \\xi_{i}\n",
    "\\end{equation}\n",
    "<br>\n",
    "\\begin{align}\n",
    "{\\text{subject to,   }}  w_{y_i}^T \\varphi(x_i) - w_{t}^{T}\\varphi(x_i) \\geq 1 - \\delta_{y_i,t} - \\xi_i\n",
    "\\end{align}\n",
    "\\begin{align}\n",
    "i = 1,...,l, t \\in {1,...,k},\n",
    "\\end{align}\n",
    "\n",
    "the constraints $\\xi_i$ ≥ 0, i = 1,...,l, are implicitly indicated in the margin constraints of when t equals $y_i$.\n",
    "\n",
    "The resulting Decision function is: \n",
    "<br>\n",
    "\\begin{align}\n",
    "argmax_m f_m(x) = argmax_m w^{T}_{m} \\varphi(x)\n",
    "\\end{align}\n",
    "<br>\n",
    "In addition, the equation focuses on classification rule, without the bias terms bm, m = 1,...,k. A nonzero bm can be easily modeled by adding an additional constant feature to each x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
